{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2296f716-b2bc-477a-88c7-651285a3d56b",
   "metadata": {},
   "source": [
    "## 1.Loading and PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a91419d-8484-4a86-8ab4-62a59786002c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61b287d7-878e-4deb-a3cd-fd513579fc17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  Target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "California_housing = fetch_california_housing()\n",
    "\n",
    "#covert to a dataframe\n",
    "df = pd.DataFrame(California_housing.data, columns=California_housing.feature_names)\n",
    "df['Target'] = California_housing.target\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc7c6a66-340c-4f99-837c-c8f2e0f6b7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      "MedInc        0\n",
      "HouseAge      0\n",
      "AveRooms      0\n",
      "AveBedrms     0\n",
      "Population    0\n",
      "AveOccup      0\n",
      "Latitude      0\n",
      "Longitude     0\n",
      "Target        0\n",
      "dtype: int64\n",
      "Missing Values:\n",
      "MedInc        0\n",
      "HouseAge      0\n",
      "AveRooms      0\n",
      "AveBedrms     0\n",
      "Population    0\n",
      "AveOccup      0\n",
      "Latitude      0\n",
      "Longitude     0\n",
      "Target        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check missing values:\n",
    "print(\"Missing Values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "#to handle missing values :\n",
    "\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "print(\"Missing Values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c9d098e-15cf-4d3c-b1b6-f5b4d102f425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.344766</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.628559</td>\n",
       "      <td>-0.153758</td>\n",
       "      <td>-0.974429</td>\n",
       "      <td>-0.049597</td>\n",
       "      <td>1.052548</td>\n",
       "      <td>-1.327835</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.332238</td>\n",
       "      <td>-0.607019</td>\n",
       "      <td>0.327041</td>\n",
       "      <td>-0.263336</td>\n",
       "      <td>0.861439</td>\n",
       "      <td>-0.092512</td>\n",
       "      <td>1.043185</td>\n",
       "      <td>-1.322844</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.782699</td>\n",
       "      <td>1.856182</td>\n",
       "      <td>1.155620</td>\n",
       "      <td>-0.049016</td>\n",
       "      <td>-0.820777</td>\n",
       "      <td>-0.025843</td>\n",
       "      <td>1.038503</td>\n",
       "      <td>-1.332827</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.932968</td>\n",
       "      <td>1.856182</td>\n",
       "      <td>0.156966</td>\n",
       "      <td>-0.049833</td>\n",
       "      <td>-0.766028</td>\n",
       "      <td>-0.050329</td>\n",
       "      <td>1.038503</td>\n",
       "      <td>-1.337818</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.012881</td>\n",
       "      <td>1.856182</td>\n",
       "      <td>0.344711</td>\n",
       "      <td>-0.032906</td>\n",
       "      <td>-0.759847</td>\n",
       "      <td>-0.085616</td>\n",
       "      <td>1.038503</td>\n",
       "      <td>-1.337818</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  2.344766  0.982143  0.628559  -0.153758   -0.974429 -0.049597  1.052548   \n",
       "1  2.332238 -0.607019  0.327041  -0.263336    0.861439 -0.092512  1.043185   \n",
       "2  1.782699  1.856182  1.155620  -0.049016   -0.820777 -0.025843  1.038503   \n",
       "3  0.932968  1.856182  0.156966  -0.049833   -0.766028 -0.050329  1.038503   \n",
       "4 -0.012881  1.856182  0.344711  -0.032906   -0.759847 -0.085616  1.038503   \n",
       "\n",
       "   Longitude  Target  \n",
       "0  -1.327835   4.526  \n",
       "1  -1.322844   3.585  \n",
       "2  -1.332827   3.521  \n",
       "3  -1.337818   3.413  \n",
       "4  -1.337818   3.422  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to initialize the scaler :\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# to scale the features:\n",
    "scaled_features = scaler.fit_transform(df.iloc[:,:-1])\n",
    "\n",
    "# convert scaled features back to a dataframe:\n",
    "scaled_df = pd.DataFrame(scaled_features, columns=California_housing.feature_names)\n",
    "scaled_df['Target']=df['Target']\n",
    "\n",
    "scaled_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2d911b-ede7-4ed0-90c0-c7e906eb9a7d",
   "metadata": {},
   "source": [
    "#### Handling Missing Values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63f550f-d674-4a23-a7d5-9e63c69b98c1",
   "metadata": {},
   "source": [
    "##### .Many machine learning models cannot handle missing values and will fail or produce errors if they remain.\n",
    "##### .Replacing missing values with the mean is a simple and effective method when then missing values are few and the data is continuous.\n",
    "##### .It prevents losing rows of data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae0f866-0a68-4c4c-9e1a-36e6ddf2ea23",
   "metadata": {},
   "source": [
    "#### Separating Features and Target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5670d176-1997-48e6-b129-d2bb23ae8328",
   "metadata": {},
   "source": [
    "##### . ML models need to be trained on input variables separately from the output the model should predict.\n",
    "##### . This separation is essential before scaling and model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3454bda5-c301-44fc-8522-51911438c243",
   "metadata": {},
   "source": [
    "#### Feature Scaling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640a510d-6ed0-41f2-a994-252064a53388",
   "metadata": {},
   "source": [
    "##### . The dataset contains features with very different numeric ranges(e.g.,population count vs median income).\n",
    "\n",
    "##### . Prevents large-value features from dominating the model.Improves numerical stability and models convergence,often improve prediction accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc64ae8a-1457-407b-b134-4028d767005e",
   "metadata": {},
   "source": [
    "We handled missing data by replacing missing values with the column mean to avoid losing data ensure smooth model training. We then Standardized all numeric features using StandardizedScaler to normalize the features distributions, which prevents scale-dependent features from dominating the model and improves the stability and performance of regression algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5795247-00fa-4db1-a836-541e06c15d40",
   "metadata": {},
   "source": [
    "## 2.Regression Algorithm Implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18d11291-8361-40a7-bb61-bc6657a9be20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "acf44c9d-4b4e-46bd-957d-fb280ccb288a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into features and target:\n",
    "X = scaled_df.iloc[:,:-1]\n",
    "y = scaled_df['Target']\n",
    "\n",
    "#split into training and testing sets:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2b608192-0460-4bca-a887-b644d506203c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\henna\\new folder\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\henna\\new folder\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\henna\\new folder\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\henna\\new folder\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\henna\\new folder\\lib\\site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c872d10c-deff-4c54-9e89-887ac7c8e00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression RMSE: 0.5558915986952442\n",
      "Linear Regession R2 Score: 0.575787706032451\n"
     ]
    }
   ],
   "source": [
    "#linear regression:\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "#predictions:\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "\n",
    "#Evaluation:\n",
    "lr_rmse = mean_squared_error(y_test, lr_predictions)\n",
    "lr_r2 = r2_score(y_test, lr_predictions)\n",
    "\n",
    "print(\"Linear Regression RMSE:\",lr_rmse)\n",
    "print(\"Linear Regession R2 Score:\",lr_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "23423825-5eb0-4c2a-8725-bbae1f7438b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree RMSE: 0.4942716777366763\n",
      "Decision Tree R2 Score: 0.6228111330554302\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Regressor:\n",
    "dt_model = DecisionTreeRegressor(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "#predictions\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "\n",
    "#evaluation:\n",
    "dt_rmse = mean_squared_error(y_test, dt_predictions)\n",
    "dt_r2 = r2_score(y_test, dt_predictions)\n",
    "\n",
    "print(\"Decision Tree RMSE:\", dt_rmse)\n",
    "print(\"Decision Tree R2 Score:\", dt_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "70e98dde-a7e4-4e98-9877-c5b1f85217e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest RMSE: 0.25549776668540763\n",
      "Random Forest R2 Score: 0.805024407701793\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Regressor:\n",
    "rf_model = RandomForestRegressor(random_state=42, n_estimators=100)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "#predictions\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "\n",
    "#evaluation\n",
    "rf_rmse = mean_squared_error(y_test, rf_predictions)\n",
    "rf_r2 = r2_score(y_test, rf_predictions)\n",
    "\n",
    "print(\"Random Forest RMSE:\",rf_rmse)\n",
    "print(\"Random Forest R2 Score:\",rf_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "48aabbd4-e652-4065-aa67-5f32e2368eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting RMSE: 0.29399901242474274\n",
      "Gradient Boosting R2 Score: 0.7756433164710084\n"
     ]
    }
   ],
   "source": [
    "# gradient Boosting Regressor:\n",
    "gb_model = GradientBoostingRegressor(random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "#predictions:\n",
    "gb_predictions = gb_model.predict(X_test)\n",
    "\n",
    "#Evaluation:\n",
    "gb_rmse = mean_squared_error(y_test, gb_predictions)\n",
    "gb_r2 = r2_score(y_test, gb_predictions)\n",
    "\n",
    "\n",
    "print(\"Gradient Boosting RMSE:\", gb_rmse)\n",
    "print(\"Gradient Boosting R2 Score:\", gb_r2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "79b957ac-808b-45d0-96ef-64991591457b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR RMSE: 0.3551984619989429\n",
      "SVR R2 Score: 0.7289407597956454\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Regressor:\n",
    "svr_model = SVR(kernel='rbf')\n",
    "svr_model.fit(X_train, y_train)\n",
    "\n",
    "#predictions\n",
    "svr_predictions = svr_model.predict(X_test)\n",
    "\n",
    "#evaluation:\n",
    "svr_rmse = mean_squared_error(y_test, svr_predictions)\n",
    "svr_r2 = r2_score(y_test, svr_predictions)\n",
    "\n",
    "print(\"SVR RMSE:\", svr_rmse)\n",
    "print(\"SVR R2 Score:\", svr_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3927dd93-b63b-46c4-9904-2315d7bad3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Model      RMSE  R2 Score\n",
      "0  Linear Regression  0.555892  0.575788\n",
      "1      Decision Tree  0.494272  0.622811\n",
      "2      Random Forest  0.255498  0.805024\n",
      "3  Gradient Boosting  0.293999  0.775643\n",
      "4                SVR  0.355198  0.728941\n"
     ]
    }
   ],
   "source": [
    "results = {\n",
    "    \"Model\":[\"Linear Regression\", \"Decision Tree\", \"Random Forest\", \"Gradient Boosting\", \"SVR\"],\n",
    "    \"RMSE\":[lr_rmse, dt_rmse, rf_rmse, gb_rmse, svr_rmse],\n",
    "    \"R2 Score\":[lr_r2, dt_r2, rf_r2, gb_r2, svr_r2]\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d958517-982b-4fe2-8f9f-03ecea346827",
   "metadata": {},
   "source": [
    "#### Linear Regression:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c294658-380d-424b-aaed-4ed98f366642",
   "metadata": {},
   "source": [
    "##### .First a straight line through the data.Assumes a linear relationship between features(X) and the target (y).\n",
    "##### .When the relationship between variables is roughly linear. Works best if the dataset is clean and not too complex.\n",
    "##### . If your datasets has non-linear patterns,performance will be poor (higher MSE,lower R^2).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592a36e1-f9e0-4422-8570-f3a596461c5a",
   "metadata": {},
   "source": [
    "#### Decision Tree Regressor:\n",
    "\n",
    "##### .Splits the data into branches based on rules(like yes/no conditions)\n",
    "##### .Creates a tree of decisions to predict the target.\n",
    "##### .Good for non-linear relationships and easy to interpret But can overfit if not pruned or limited in depth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf73201-c080-407d-bddd-6ba33e854287",
   "metadata": {},
   "source": [
    "#### Random Forest Regressor:\n",
    "\n",
    "##### .Builds many decision trees,each trained on different random samples and takes the average prediction of all trees.\n",
    "##### .Reduces overfitting compared to a single tree and handles non-linear data well.\n",
    "##### .Good general performance on many datasets. Often gives one of the best results,which seems to match your output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db49aa7-d003-4709-8530-045e6e77293e",
   "metadata": {},
   "source": [
    "#### Gradient Boosting Regressor:\n",
    "\n",
    "##### .Builds trees sequentially,where each new tree focuses on fixing the errors of the previous one.\"Boosts\" performance gradually.\n",
    "##### .Powerful for complex datasets, Often performs even better than random forest when tuned well.But more sensitive to parameter settings and noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1ad24e-6e69-44bd-ad0c-017f2050f402",
   "metadata": {},
   "source": [
    "#### Support Vector Regression(SVR)\n",
    "\n",
    "##### .Tries to fit data within a margin(tube) rather than minimizing error directly.\n",
    "##### .Can Model non-linear data using kernel functions.\n",
    "##### .Works well with smaller datasets.Good when relationships are non-linear but not extremely complex.But be slow and require Scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53cd8cd-cf69-4c7d-963f-3ae1d6160148",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "From the results Gradient Boosting or Random Forest likely performed the best. They handle non-linear relationships well,they handle complex interactions between features and they reduce overfitting (Random Forest) or Correct errors step-by-step(Gradient-Boosting).\n",
    "\n",
    "if the dataset isn't perfectly linear (which is very common in real-world data),these models will generally outperform Linear Regression and SVR.\n",
    "\n",
    "\n",
    "The Random Forest and Gradient Boosting regressors work well for this dataset because they are able to model complex and non-linear relationships between the features and the target variable. Random Forest reduces overfitting by averaging predictions across many decisions trees, while Gradient Boosting improves performance by sequentially correcting the errors of previous models.This makes tham more accurate and robust compared to linear Regression, Which assumes a purely linear relationship that may not exist in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08731bd-5e37-4043-8fba-e19812316635",
   "metadata": {},
   "source": [
    "### 3.Model Evaluation and Comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cea872ac-3ef3-4daf-98fd-5d88c3948509",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6a4fbba3-8382-4dd8-a37a-0834496ef2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Metrics:\n",
      "MSE: 0.5558915986952442\n",
      "MAE: 0.5332001304956565\n",
      "R2: 0.575787706032451\n"
     ]
    }
   ],
   "source": [
    "#linear regression evaluation\n",
    "lr_mse = mean_squared_error(y_test, lr_predictions)\n",
    "lr_mae = mean_absolute_error(y_test, lr_predictions)\n",
    "lr_r2 = r2_score(y_test, lr_predictions)\n",
    "\n",
    "\n",
    "print(\"Linear Regression Metrics:\")\n",
    "print(\"MSE:\", lr_mse)\n",
    "print(\"MAE:\", lr_mae)\n",
    "print(\"R2:\" ,lr_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e4a9a47a-b716-440e-a92f-3c6db11fb001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regressor Metrics:\n",
      "MSE: 0.4942716777366763\n",
      "MAE: 0.4537843265503876\n",
      "R²: 0.6228111330554302\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Regressor Evaluation:\n",
    "dt_mse = mean_squared_error(y_test, dt_predictions)\n",
    "dt_mae = mean_absolute_error(y_test, dt_predictions)\n",
    "dt_r2 = r2_score(y_test, dt_predictions)\n",
    "\n",
    "print(\"Decision Tree Regressor Metrics:\")\n",
    "print(\"MSE:\", dt_mse)\n",
    "print(\"MAE:\", dt_mae)\n",
    "print(\"R²:\", dt_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a908360f-571b-4d3d-9b3c-93ab131a33bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor Metrics:\n",
      "MSE: 0.25549776668540763\n",
      "MAE: 0.32761306601259704\n",
      "R²: 0.805024407701793\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Regressor Evaluation:\n",
    "rf_mse = mean_squared_error(y_test, rf_predictions)\n",
    "rf_mae = mean_absolute_error(y_test, rf_predictions)\n",
    "rf_r2 = r2_score(y_test, rf_predictions)\n",
    "\n",
    "print(\"Random Forest Regressor Metrics:\")\n",
    "print(\"MSE:\", rf_mse)\n",
    "print(\"MAE:\", rf_mae)\n",
    "print(\"R²:\", rf_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "81fcb818-7745-4aee-bcfa-e208f4f9e5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regressor Metrics:\n",
      "MSE: 0.29399901242474274\n",
      "MAE: 0.37165044848436773\n",
      "R²: 0.7756433164710084\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Regressor Evaluation:\n",
    "gb_mse = mean_squared_error(y_test, gb_predictions)\n",
    "gb_mae = mean_absolute_error(y_test, gb_predictions)\n",
    "gb_r2 = r2_score(y_test, gb_predictions)\n",
    "\n",
    "print(\"Gradient Boosting Regressor Metrics:\")\n",
    "print(\"MSE:\", gb_mse)\n",
    "print(\"MAE:\", gb_mae)\n",
    "print(\"R²:\", gb_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "187f3e68-6919-4bdc-9fdd-060afb05d0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Regressor Metrics:\n",
      "MSE: 0.3551984619989429\n",
      "MAE: 0.397763096343787\n",
      "R²: 0.7289407597956454\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Regressor Evaluation:\n",
    "svr_mse = mean_squared_error(y_test, svr_predictions)\n",
    "svr_mae = mean_absolute_error(y_test, svr_predictions)\n",
    "svr_r2 = r2_score(y_test, svr_predictions)\n",
    "\n",
    "print(\"Support Vector Regressor Metrics:\")\n",
    "print(\"MSE:\", svr_mse)\n",
    "print(\"MAE:\", svr_mae)\n",
    "print(\"R²:\", svr_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "692499f8-63fe-439c-8ed1-1e7be4524b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Model       MSE       MAE        R²\n",
      "0  Linear Regression  0.555892  0.533200  0.575788\n",
      "1      Decision Tree  0.494272  0.453784  0.622811\n",
      "2      Random Forest  0.255498  0.327613  0.805024\n",
      "3  Gradient Boosting  0.293999  0.371650  0.775643\n",
      "4                SVR  0.355198  0.397763  0.728941\n"
     ]
    }
   ],
   "source": [
    "#  create a DataFrame to compare results:\n",
    "results = {\n",
    "    \"Model\": [\"Linear Regression\", \"Decision Tree\", \"Random Forest\", \"Gradient Boosting\", \"SVR\"],\n",
    "    \"MSE\": [lr_mse, dt_mse, rf_mse, gb_mse, svr_mse],\n",
    "    \"MAE\": [lr_mae, dt_mae, rf_mae, gb_mae, svr_mae],\n",
    "    \"R²\": [lr_r2, dt_r2, rf_r2, gb_r2, svr_r2],\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(results)\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182381de-ec9f-42ff-89ae-f4402faf4a2f",
   "metadata": {},
   "source": [
    "#### Model Performance Analysis:\n",
    "\n",
    "##### The objective for error metrics like MSE and MAE is to be as low as possible ,with 0 indicating a perfect model. For R^2, which measures the proportion of variance explained,the goal is to be close to 1(or"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680abe15-5244-4a6c-a012-0edeee5f2ccc",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "#### Best Performing Algorithm:Random Forest Regressor\n",
    "\n",
    "##### The Random Forest model performs best across all metrics:\n",
    "\n",
    "##### .It has the lowest MSE(0.255), meaning the average squared difference between predicted and actual values is minimized, penalizing larger errors efffectively.\n",
    "##### .I t has the lowest MAE(0.327), indicating its predictions are , on average , the closest in absloute distance to the actual data points.\n",
    "##### .It achieves the highest R^2 Score (0.805 or 80.5%), meaning it explains the largest proportion of the variance in the largest variable compared to all other models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607bf58a-e1f7-46af-b734-31c154690d75",
   "metadata": {},
   "source": [
    "#### Worst Performing Alogorithm: Linear Regression\n",
    "\n",
    "##### The Linear Regression model is the worst performer across all metrics:\n",
    "\n",
    "##### .It has the highest MSE(0.555) and highest MAE(0.533), indicating its predictions are the least accurate and furtheat from the actual values on average.\n",
    "##### .It has the lowest R^2score (0.575),suggesting it explains the least amount of the target variables variance compared to the other four models tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e717e3-8681-4312-85e0-d708c6abaa8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87ca076-ede5-40bd-9067-a2af99814e84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:New folder]",
   "language": "python",
   "name": "conda-env-New_folder-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
